﻿﻿﻿﻿﻿﻿﻿本文链接：[https://blog.csdn.net/xiegh2014/article/details/52132863](https://blog.csdn.net/xiegh2014/article/details/52132863)版权声明：本文为博主原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接和本声明。#CTCDN系统优化参数```cat /etc/sysctl.conf```#关闭ipv6```net.ipv6.conf.all.disable_ipv6 = 1net.ipv6.conf.default.disable_ipv6 = 1```# 避免放大攻击```net.ipv4.icmp_echo_ignore_broadcasts = 1```# 开启恶意icmp错误消息保护```net.ipv4.icmp_ignore_bogus_error_responses = 1```#关闭路由转发```net.ipv4.ip_forward = 0net.ipv4.conf.all.send_redirects = 0net.ipv4.conf.default.send_redirects = 0```#开启反向路径过滤```net.ipv4.conf.all.rp_filter = 1net.ipv4.conf.default.rp_filter = 1```#处理无源路由的包```net.ipv4.conf.all.accept_source_route = 0net.ipv4.conf.default.accept_source_route = 0```#关闭sysrq功能```kernel.sysrq = 0```#core文件名中添加pid作为扩展名```kernel.core_uses_pid = 1```# 开启SYN洪水攻击保护```net.ipv4.tcp_syncookies = 1```#修改消息队列长度```kernel.msgmnb = 65536kernel.msgmax = 65536```#设置最大内存共享段大小bytes```kernel.shmmax = 68719476736kernel.shmall = 4294967296```#timewait的数量，默认180000```net.ipv4.tcp_max_tw_buckets = 6000net.ipv4.tcp_sack = 1net.ipv4.tcp_window_scaling = 1net.ipv4.tcp_rmem = 4096        87380   4194304net.ipv4.tcp_wmem = 4096        16384   4194304net.core.wmem_default = 8388608net.core.rmem_default = 8388608net.core.rmem_max = 16777216net.core.wmem_max = 16777216```#每个网络接口接收数据包的速率比内核处理这些包的速率快时，允许送到队列的数据包的最大数目```net.core.netdev_max_backlog = 262144```#限制仅仅是为了防止简单的DoS 攻击```net.ipv4.tcp_max_orphans = 3276800```#未收到客户端确认信息的连接请求的最大值```net.ipv4.tcp_max_syn_backlog = 262144net.ipv4.tcp_timestamps = 0```#内核放弃建立连接之前发送SYNACK 包的数量```net.ipv4.tcp_synack_retries = 1```#内核放弃建立连接之前发送SYN 包的数量```net.ipv4.tcp_syn_retries = 1```#启用timewait 快速回收```net.ipv4.tcp_tw_recycle = 1```#开启重用。允许将TIME-WAIT sockets 重新用于新的TCP 连接```net.ipv4.tcp_tw_reuse = 1net.ipv4.tcp_mem = 94500000 915000000 927000000net.ipv4.tcp_fin_timeout = 1```#当keepalive 起用的时候，TCP 发送keepalive 消息的频度。缺省是2 小时```net.ipv4.tcp_keepalive_time = 30```#允许系统打开的端口范围```net.ipv4.ip_local_port_range = 1024    65000```#修改防火墙表大小，默认65536```Ulimit –n 265535```　 在Linux平台上，无论编写客户端程序还是服务端程序，在进行高并发TCP连接处理时，最高的并发数量都要受到系统对用户单一进程同时可打开文件数量的限制(这是因为系统为每个TCP连接都要创建一个socket句柄，每个socket句柄同时也是一个文件句柄)，这个数字可以设的更大。此命令是临时更改，也可以通过修改文件/etc/security/limits.conf```fs.file-max = 265535```系统级别的能够打开的文件句柄的数量,ulimit 是进程级别的```net.ipv4.ip_conntrack_max=265535```系统允许的最大跟踪连接条目。在/etc/sysctl.conf文件中增加此属性，并运行>/sbin/sysctl.conf –p另外在sysctl -p的时候A报error: 'net.ipv4.ip_conntrack_max' is an unknown key ,通过以下命令修正：```modprobe ip_conntrackecho "modprobe ip_conntrack" >> /etc/rc.local``````#net.netfilter.nf_conntrack_max=655350#net.netfilter.nf_conntrack_tcp_timeout_established=1200```# 确保无人能修改路由表```net.ipv4.conf.all.accept_redirects = 0net.ipv4.conf.default.accept_redirects = 0net.ipv4.conf.all.secure_redirects = 0net.ipv4.conf.default.secure_redirects = 0net.nf_conntrack_max = 6553600```把参数添加到/etc/sysctl.conf中，然后执行sysctl -p使参数生效，永久生效# somaxconn参数.在Linux中，/proc/sys/net/core/somaxconn这个参数，linux中内核的一个不错的参数somaxconn看下其解析：对于一个TCP连接，Server与Client需要通过三次握手来建立网络连接.当三次握手成功后,我们可以看到端口的状态由LISTEN转变为ESTABLISHED,接着这条链路上就可以开始传送数据了.每一个处于监听(Listen)状态的端口,都有自己的监听队列.监听队列的长度,与如下两方面有关:1. somaxconn参数.2. 使用该端口的程序中listen()函数.---```　　关于somaxconn参数:　　定义了系统中每一个端口最大的监听队列的长度,这是个全局的参数,默认值为128,具体信息为:　　Purpose: Specifies the maximum listen backlog.　　Values: Default: 128 connections　　Range: 0 to MAXSHORT　　Type: Connect　　Diagnosis: N/A　　Tuning: Increase this parameter on busy Web servers to handle peak connection rates.```看下FREEBSD的解析：```限制了接收新 TCP 连接侦听队列的大小。对于一个经常处理新连接的高负载 web服务环境来说，默认的 128 太小了。大多数环境这个值建议增加到 1024 或者更多。 服务进程会自己限制侦听队列的大小(例如 sendmail(8) 或者 Apache)，常常在它们的配置文件中有设置队列大小的选项。大的侦听队列对防止拒绝服务 DoS 攻击也会有所帮助。```我们可以通过，```echo 65535 >/proc/sys/net/core/somaxconn```来修改这个参数。# 修改swappinessLinux内核参数vm.swappiness，值的范围为0~100，表示系统什么时候开始进行物理内存与虚拟内存的交换。举个例子，系统总内存为64G，vm.swappiness为60，表示在系统内存使用64*0.4=25.6G的时候开始物理内存与虚拟内存的交换，这个动作势必会影响系统的性能。因此，Cloudera建议把这个值修改为1~10，最好设置为1。在/etc/sysctl.conf添加```vm.swappiness = 1```# 禁止透明大页ORACLE官方不建议我们使用RedHat 6, OEL 6, SLES 11 and UEK2 kernels 时的开启透明大页（Transparent HugePages ）， 因为透明大页（Transparent HugePages ） 存在一些问题：```        1.在RAC环境下 透明大页（Transparent HugePages ）会导致异常节点重启，和性能问题；        2.在单机环境中，透明大页（Transparent HugePages ） 也会导致一些异常的性能问题；```首先查看透明大页是否启用，[always] never表示已启用，always [never]表示已禁用```[root@n12 ~]# cat /sys/kernel/mm/redhat_transparent_hugepage/defrag[always] madvise never```如果是启用状态，修改/etc/rc.local文件并添加```echo never > /sys/kernel/mm/redhat_transparent_hugepage/defrag```避免重启系统，可以执行一遍添加命令，就不用重启系统生效。```cat /etc/sysctl.conf```# 不要启用 net.ipv4.tcp_tw_recycle```不要启用 net.ipv4.tcp_tw_recycle```如果不小心启用了，那么在/etc/sysctl.conf中注释掉在用sysctl -p是不启作用的。两种办法：方法一：```1. 把net.ipv4.tcp_tw_recycle=0 然后再sysctl -p2. 去/proc/sys/net/ipv4/中找到tcp_tw_recycle的配置文件，然后改成0```方法二：```netstat -n | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}'   ```